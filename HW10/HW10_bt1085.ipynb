{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#HW 10 CLUSTERING BUSINESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#cluster time trends in NYC businesses: \n",
    "#DATA\n",
    "#Census Business data:\n",
    "##download census data for businesses by ZIP code. the data is here\n",
    "http://www.census.gov/econ/cbp/download/\n",
    "##and it can be downloaded by hand. you can also download it with 3 terminal commands as follows: the data from 1993 through 2001 is different in the format of its path than the data after 2001 (that is why more than one for loop is needed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# $ for ((y=93; y<=99; y+=1)); do wget ftp://ftp.census.gov/Econ2001_And_Earlier/CBP_CSV/zbp$y\\totals.zip; done\n",
    "\n",
    "# $ for ((y=0; y<=9; y+=1)); do wget ftp://ftp.census.gov/econ200$y\\/CBP_CSV/zbp0$y\\totals.zip; done\n",
    "\n",
    "# $ for ((y=10; y<=15; y+=1)); do wget ftp://ftp.census.gov/econ20$y\\/CBP_CSV/zbp$y\\totals.zip; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#NYC zip codes shape file is here\n",
    "##http://data.nycprepared.org/dataset/nyc-zip-code-tabulation-areas/resource/0c0e14e9-78e1-404e-97b0-c2fabceb3981\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES: \n",
    "to read in a zip file without unzipping it you can use the pandas and zipfile packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile \n",
    "import glob, os\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import json\n",
    "import urllib2\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "#NYC zip codes shape file\n",
    "url = \"https://nycdatastables.s3.amazonaws.com/2013-08-19T18:18:28.877Z/nyc-zip-code-tabulation-areas-polygons.geojson\"\n",
    "request = urllib2.urlopen(url)\n",
    "nyczip = json.load(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nyc_zip = []\n",
    "for department in nyczip['features']:\n",
    "    nyc_zip.append(str(department['properties'][\"postalCode\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\".\")\n",
    "\n",
    "fname = \"zbp00totals.zip\"\n",
    "zf = zipfile.ZipFile(fname)\n",
    "biz = pd.read_csv(zf.open(fname.replace('.zip','.txt')))\n",
    "biz = df.rename(columns={'zip': 'ZIP', 'est': 'EST'})\n",
    "biz_est_zip_year = biz[['ZIP', 'EST']]\n",
    "biz_est_zip_year = biz_est_zip_year[(biz_est_zip_year.ZIP.astype(str).isin(nyc_zip))]\n",
    "biz_est_zip_year['YEAR'] = 2000\n",
    "\n",
    "for fname in glob.glob(\"*.zip\"):\n",
    "    if fname == \"zbp00totals.zip\":\n",
    "        continue\n",
    "    zf = zipfile.ZipFile(fname)\n",
    "    df = pd.read_csv(zf.open(fname.replace('.zip','.txt')))\n",
    "    df = df.rename(columns={'zip': 'ZIP', 'est': 'EST'})\n",
    "    df = df[['ZIP', 'EST']]\n",
    "    df = df[(df.ZIP.astype(str).isin(nyc_zip))]\n",
    "    if int(fname[3:5]) > 93:\n",
    "        df['YEAR'] = int('19' + fname[3:5])\n",
    "    else:\n",
    "        df['YEAR'] = int('20' + fname[3:5])\n",
    "    biz_est_zip_year = biz_est_zip_year.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biz_est_zip = pd.DataFrame(np.nan,index=sorted(unique(biz_est_zip_year.ZIP)),columns=range(1994,2014))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001    6999\n",
       "Name: 1994, dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz_est_zip.loc[biz_est_zip.index==10001][1994]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for z in biz_est_zip.index:\n",
    "    for y in biz_est_zip.columns:\n",
    "        biz_est = biz_est_zip_year[(biz_est_zip_year.ZIP == int(z)) * (biz_est_zip_year.YEAR == y)]\n",
    "        if len(biz_est) != 0 and 0 in biz_est.EST.keys():\n",
    "            biz_est_zip.loc[biz_est_zip.index==z][y] = 1 #int(biz_est.EST[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = biz_est_zip_year[(biz_est_zip_year.ZIP == 10001) * (biz_est_zip_year.YEAR == 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you may need to clean your data: for some NYC zip codes there may be no info\n",
    "    \n",
    "sanity check: you should have 20 (Ntimestamps) datapoints per time series and about 250 zipcodes (Nzipcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "IMPORTANT: we talked about the importance of \"whitening\" your data: dividing each feature by its standard deviation. \n",
    "Whitenings decorrelates the data: it makes the features independent so that the data covariance matrix is the identity matrix.\n",
    "Whitening your data in time series analysis is in most cases **wrong**: you are modifying your time behaviour. This is because of the strong correlation between features (two consecutive time stamps for the same observation, the same zip code here, are strongly correlated). Here instead you want to standardize your time series: subtract the mean and divide each time series (separately) by its standard deviation. As a sanity check (if you use skitlearn Kmeans or skitlearns kmeans2): you want your data array to be shaped Nzipcodes x Ntimestamps\n",
    "\n",
    "mydata.shape should be (Nzipcodes, Ntimestamps)\n",
    "\n",
    "mydata[i].std() shoould be 1 for all i in range(len(Nzipcodes))\n",
    "\n",
    "mydata[i].mean() should be ~0 for all i in range(len(Nzipcodes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "TASKS:\n",
    "    \n",
    "    1. get and prep your data.\n",
    "    2. cluster the NUMBER OF ESTABLISHMENTS time series with K-means in **a few** clusters (as discussed there is no real good, sound way to decide what a good number is here. try a few options, keeping in mind a few is more than a couple, but i recommand you stay within the single digit numbers)\n",
    "    3. plot the cluster centers (if you used K means those are the means of the clusters). you can plot for example the cluster centers overlayed on each time series (using the alpha channel to control the opacity in the plot may be helpful here).\n",
    "    4. Use another clustering algorithm (of your choice)\n",
    "    5. overlay your data on a NYC map: you can use shapefiles for the zip codes and different colors for different clusters\n",
    "    6. Compare the results of the 2 algorithms\n",
    "    7. attempt an interpretation. this is dangerous ground: clustering is an exploratory tool so you do not want to jump to conclusions because you see some clusters! but seeing structure in your data can inform your next moves as an investigator. \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
